import os
import logging
from datetime import datetime
from typing import List, Dict, Any, Optional
from werkzeug.utils import secure_filename
import json
from google.cloud import storage
from google.cloud.exceptions import NotFound

logger = logging.getLogger(__name__)

class CloudStorage:
    """Google Cloud Storage í´ë˜ìŠ¤"""
    
    def __init__(self, bucket_name: str, project_id: str, is_cloud_run: bool = True):
        self.bucket_name = bucket_name
        self.project_id = project_id
        self.is_cloud_run = is_cloud_run
        
        # Cloud Storage í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” (ì¬ì‹œë„ ë¡œì§ í¬í•¨)
        self.client = None
        self.bucket = None
        self._initialize_client_with_retry()
    
    def _initialize_client_with_retry(self, max_retries: int = 3):
        """ì¬ì‹œë„ ë¡œì§ì„ í¬í•¨í•œ í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”"""
        for attempt in range(max_retries):
            try:
                logger.info(f"ğŸ”„ Cloud Storage í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì‹œë„ {attempt + 1}/{max_retries}")
                
                # Cloud Storage í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” (ê¸°ë³¸ ë°©ì‹)
                self.client = storage.Client(project=self.project_id)
                self.bucket = self.client.bucket(self.bucket_name)
                
                # ì—°ê²° í…ŒìŠ¤íŠ¸ (ê°„ë‹¨í•œ ë²„í‚· ì¡´ì¬ í™•ì¸)
                try:
                    bucket_exists = self.bucket.exists()
                    logger.info(f"âœ… Cloud Storage ì´ˆê¸°í™” ì™„ë£Œ: {self.bucket_name} (ë²„í‚· ì¡´ì¬: {bucket_exists})")
                    return
                except Exception as test_error:
                    logger.warning(f"âš ï¸ ì—°ê²° í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨, ì¬ì‹œë„: {test_error}")
                    raise test_error
                    
            except Exception as e:
                logger.warning(f"âš ï¸ Cloud Storage ì´ˆê¸°í™” ì‹¤íŒ¨ (ì‹œë„ {attempt + 1}/{max_retries}): {e}")
                
                if attempt < max_retries - 1:
                    import time
                    wait_time = (attempt + 1) * 2  # 2, 4, 6ì´ˆ ëŒ€ê¸°
                    logger.info(f"â³ {wait_time}ì´ˆ í›„ ì¬ì‹œë„...")
                    time.sleep(wait_time)
                else:
                    logger.error(f"âŒ Cloud Storage ì´ˆê¸°í™” ìµœì¢… ì‹¤íŒ¨: {e}")
                    # ì´ˆê¸°í™” ì‹¤íŒ¨í•´ë„ í´ë¼ì´ì–¸íŠ¸ëŠ” Noneìœ¼ë¡œ ìœ ì§€í•˜ì—¬ ë‚˜ì¤‘ì— ì¬ì‹œë„ ê°€ëŠ¥
                    self.client = None
                    self.bucket = None
                    raise
    
    def upload_file(self, file) -> str:
        """íŒŒì¼ì„ Cloud Storageì— ì—…ë¡œë“œ"""
        try:
            # ì›ë³¸ íŒŒì¼ëª… ì €ì¥
            original_filename = file.filename
            # ì•ˆì „í•œ íŒŒì¼ëª… ìƒì„±
            secure_name = secure_filename(original_filename)
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            stored_filename = f"{timestamp}_{secure_name}"
            
            # Cloud Storageì— ì—…ë¡œë“œ
            blob = self.bucket.blob(f"documents/{stored_filename}")
            blob.upload_from_file(file)
            
            # ë©”íƒ€ë°ì´í„° ì €ì¥
            metadata = {
                'original_name': original_filename,
                'stored_name': stored_filename,
                'size': blob.size,
                'uploaded_at': datetime.now().isoformat(),
                'content_type': blob.content_type,
                'has_embedding': False,
                'updated_at': datetime.now().isoformat()
            }
            
            # ë©”íƒ€ë°ì´í„°ë¥¼ ë³„ë„ íŒŒì¼ë¡œ ì €ì¥
            metadata_blob = self.bucket.blob(f"metadata/{stored_filename}.json")
            metadata_blob.upload_from_string(
                json.dumps(metadata, ensure_ascii=False, indent=2),
                content_type='application/json'
            )
            
            logger.info(f"âœ… íŒŒì¼ ì—…ë¡œë“œ ì™„ë£Œ: {original_filename} -> {stored_filename}")
            return f"gs://{self.bucket_name}/documents/{stored_filename}"
            
        except Exception as e:
            logger.error(f"âŒ íŒŒì¼ ì—…ë¡œë“œ ì‹¤íŒ¨: {e}")
            raise
    
    def download_file(self, file_url: str) -> bytes:
        """Cloud Storageì—ì„œ íŒŒì¼ ë‹¤ìš´ë¡œë“œ"""
        try:
            if file_url.startswith('gs://'):
                # gs://bucket/path í˜•ì‹ì—ì„œ ê²½ë¡œ ì¶”ì¶œ
                path = file_url.replace(f"gs://{self.bucket_name}/", "")
                blob = self.bucket.blob(path)
                
                if not blob.exists():
                    logger.error(f"âŒ íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŒ: {path}")
                    raise FileNotFoundError(f"íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {path}")
                
                content = blob.download_as_bytes()
                logger.info(f"âœ… Cloud Storageì—ì„œ íŒŒì¼ ë‹¤ìš´ë¡œë“œ ì„±ê³µ: {len(content)} bytes")
                return content
            else:
                # ë¡œì»¬ íŒŒì¼ ê²½ë¡œì¸ ê²½ìš°
                if not os.path.exists(file_url):
                    logger.error(f"âŒ ë¡œì»¬ íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŒ: {file_url}")
                    raise FileNotFoundError(f"íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {file_url}")
                
                with open(file_url, 'rb') as f:
                    content = f.read()
                logger.info(f"âœ… ë¡œì»¬ íŒŒì¼ì—ì„œ ë‹¤ìš´ë¡œë“œ ì„±ê³µ: {len(content)} bytes")
                return content
        except Exception as e:
            logger.error(f"âŒ íŒŒì¼ ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨: {e}")
            import traceback
            logger.error(f"âŒ ìƒì„¸ ì˜¤ë¥˜: {traceback.format_exc()}")
            raise
    
    def get_metadata(self) -> Dict[str, Any]:
        """ëª¨ë“  íŒŒì¼ì˜ ë©”íƒ€ë°ì´í„° ì¡°íšŒ (ì¬ì‹œë„ ë¡œì§ í¬í•¨)"""
        max_retries = 3
        for attempt in range(max_retries):
            try:
                # í´ë¼ì´ì–¸íŠ¸ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì€ ê²½ìš° ì¬ì‹œë„
                if not self.client or not self.bucket:
                    logger.info(f"ğŸ”„ í´ë¼ì´ì–¸íŠ¸ ì¬ì´ˆê¸°í™” ì‹œë„ {attempt + 1}/{max_retries}")
                    try:
                        self._initialize_client_with_retry()
                    except Exception as init_error:
                        logger.error(f"âŒ í´ë¼ì´ì–¸íŠ¸ ì¬ì´ˆê¸°í™” ì‹¤íŒ¨: {init_error}")
                        if attempt < max_retries - 1:
                            continue
                        else:
                            return {}
                
                metadata = {}
                blobs = self.bucket.list_blobs(prefix="metadata/")
                
                for blob in blobs:
                    if blob.name.endswith('.json'):
                        try:
                            content = blob.download_as_text()
                            data = json.loads(content)
                            # íŒŒì¼ëª…ì—ì„œ .json ì œê±°
                            filename = blob.name.replace("metadata/", "").replace(".json", "")
                            metadata[filename] = data
                        except Exception as e:
                            logger.warning(f"âš ï¸ ë©”íƒ€ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {blob.name} - {e}")
                
                return metadata
                
            except Exception as e:
                logger.warning(f"âš ï¸ ë©”íƒ€ë°ì´í„° ì¡°íšŒ ì‹¤íŒ¨ (ì‹œë„ {attempt + 1}/{max_retries}): {e}")
                
                if attempt < max_retries - 1:
                    import time
                    wait_time = (attempt + 1) * 2
                    logger.info(f"â³ {wait_time}ì´ˆ í›„ ì¬ì‹œë„...")
                    time.sleep(wait_time)
                else:
                    logger.error(f"âŒ ë©”íƒ€ë°ì´í„° ì¡°íšŒ ìµœì¢… ì‹¤íŒ¨: {e}")
                    return {}
    
    def mark_embedding_status(self, filename: str, has_embedding: bool):
        """ì„ë² ë”© ìƒíƒœ ì—…ë°ì´íŠ¸"""
        try:
            # ë¨¼ì € ì›ë³¸ íŒŒì¼ëª…ìœ¼ë¡œ ë©”íƒ€ë°ì´í„° ì°¾ê¸°
            metadata = self.get_metadata()
            target_metadata_blob = None
            found_filename = None
            
            # ì›ë³¸ íŒŒì¼ëª…ìœ¼ë¡œ ì°¾ê¸°
            for stored_filename, file_metadata in metadata.items():
                if file_metadata.get('original_name') == filename:
                    target_metadata_blob = self.bucket.blob(f"metadata/{stored_filename}.json")
                    found_filename = stored_filename
                    break
            
            # ì›ë³¸ íŒŒì¼ëª…ìœ¼ë¡œ ì°¾ì§€ ëª»í•œ ê²½ìš°, ì €ì¥ëœ íŒŒì¼ëª…ìœ¼ë¡œ ì‹œë„
            if not target_metadata_blob:
                # ì €ì¥ëœ íŒŒì¼ëª…ìœ¼ë¡œ ì§ì ‘ ì‹œë„
                if filename in metadata:
                    target_metadata_blob = self.bucket.blob(f"metadata/{filename}.json")
                    found_filename = filename
                else:
                    # í™•ì¥ì ì œê±°í•˜ê³  ì‹œë„
                    filename_without_ext = filename.rsplit('.', 1)[0] if '.' in filename else filename
                    for stored_filename, file_metadata in metadata.items():
                        if stored_filename == filename or stored_filename.startswith(filename_without_ext):
                            target_metadata_blob = self.bucket.blob(f"metadata/{stored_filename}.json")
                            found_filename = stored_filename
                            break
            
            if target_metadata_blob and target_metadata_blob.exists():
                # ê¸°ì¡´ ë©”íƒ€ë°ì´í„° ë¡œë“œ
                content = target_metadata_blob.download_as_text()
                metadata_data = json.loads(content)
                
                # ì„ë² ë”© ìƒíƒœ ì—…ë°ì´íŠ¸
                metadata_data['has_embedding'] = has_embedding
                metadata_data['updated_at'] = datetime.now().isoformat()
                
                # ì—…ë°ì´íŠ¸ëœ ë©”íƒ€ë°ì´í„° ì €ì¥
                target_metadata_blob.upload_from_string(
                    json.dumps(metadata_data, ensure_ascii=False, indent=2),
                    content_type='application/json'
                )
                
                logger.info(f"âœ… ì„ë² ë”© ìƒíƒœ ì—…ë°ì´íŠ¸: {filename} -> {has_embedding} (ë©”íƒ€ë°ì´í„°: {found_filename})")
            else:
                logger.warning(f"âš ï¸ ë©”íƒ€ë°ì´í„° íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ: {filename}")
                # ë””ë²„ê¹…ì„ ìœ„í•´ ë©”íƒ€ë°ì´í„° ëª©ë¡ ì¶œë ¥
                logger.info(f"â„¹ï¸ ì‚¬ìš© ê°€ëŠ¥í•œ ë©”íƒ€ë°ì´í„° íŒŒì¼ë“¤: {list(metadata.keys())}")
                
        except Exception as e:
            logger.error(f"âŒ ì„ë² ë”© ìƒíƒœ ì—…ë°ì´íŠ¸ ì‹¤íŒ¨: {e}")
            import traceback
            logger.error(f"âŒ ìƒì„¸ ì˜¤ë¥˜: {traceback.format_exc()}")
    
    def delete_file(self, filename: str) -> bool:
        """íŒŒì¼ ì‚­ì œ"""
        try:
            # ë¨¼ì € ë©”íƒ€ë°ì´í„°ì—ì„œ ì‹¤ì œ ì €ì¥ëœ íŒŒì¼ëª… ì°¾ê¸°
            metadata = self.get_metadata()
            stored_filename = None
            
            # ì›ë³¸ íŒŒì¼ëª…ìœ¼ë¡œ ì°¾ê¸°
            for stored_name, file_metadata in metadata.items():
                if file_metadata.get('original_name') == filename:
                    stored_filename = stored_name
                    break
            
            # ì›ë³¸ íŒŒì¼ëª…ìœ¼ë¡œ ì°¾ì§€ ëª»í•œ ê²½ìš°, ì €ì¥ëœ íŒŒì¼ëª…ìœ¼ë¡œ ì‹œë„
            if not stored_filename:
                stored_filename = filename
            
            # ë¬¸ì„œ íŒŒì¼ ì‚­ì œ
            doc_blob = self.bucket.blob(f"documents/{stored_filename}")
            if doc_blob.exists():
                doc_blob.delete()
                logger.info(f"âœ… ë¬¸ì„œ íŒŒì¼ ì‚­ì œ: {stored_filename}")
            else:
                logger.warning(f"âš ï¸ ë¬¸ì„œ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ: {stored_filename}")
            
            # ë©”íƒ€ë°ì´í„° íŒŒì¼ ì‚­ì œ
            metadata_blob = self.bucket.blob(f"metadata/{stored_filename}.json")
            if metadata_blob.exists():
                metadata_blob.delete()
                logger.info(f"âœ… ë©”íƒ€ë°ì´í„° íŒŒì¼ ì‚­ì œ: {stored_filename}.json")
            else:
                logger.warning(f"âš ï¸ ë©”íƒ€ë°ì´í„° íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ: {stored_filename}.json")
            
            logger.info(f"âœ… íŒŒì¼ ì‚­ì œ ì™„ë£Œ: {filename} (ì €ì¥ëœ íŒŒì¼ëª…: {stored_filename})")
            return True
            
        except Exception as e:
            logger.error(f"âŒ íŒŒì¼ ì‚­ì œ ì‹¤íŒ¨: {e}")
            return False
    
    def list_files(self) -> List[Dict[str, Any]]:
        """íŒŒì¼ ëª©ë¡ ì¡°íšŒ"""
        try:
            files = []
            metadata = self.get_metadata()
            
            for filename, file_metadata in metadata.items():
                files.append({
                    'name': file_metadata.get('original_name', filename),
                    'filename': filename,
                    'size': file_metadata.get('size', 0),
                    'size_mb': round(file_metadata.get('size', 0) / (1024 * 1024), 2),
                    'uploaded_at': file_metadata.get('uploaded_at', ''),
                    'created': file_metadata.get('uploaded_at', ''),
                    'updated': file_metadata.get('updated_at', file_metadata.get('uploaded_at', '')),
                    'has_embedding': file_metadata.get('has_embedding', False),
                    'url': f"gs://{self.bucket_name}/documents/{filename}",
                    'content_type': file_metadata.get('content_type', '')
                })
            
            # ì—…ë¡œë“œ ì‹œê°„ìˆœìœ¼ë¡œ ì •ë ¬
            files.sort(key=lambda x: x.get('uploaded_at', ''), reverse=True)
            
            logger.info(f"âœ… íŒŒì¼ ëª©ë¡ ì¡°íšŒ ì™„ë£Œ: {len(files)}ê°œ íŒŒì¼")
            return files
            
        except Exception as e:
            logger.error(f"âŒ íŒŒì¼ ëª©ë¡ ì¡°íšŒ ì‹¤íŒ¨: {e}")
            return []
    
    def delete_multiple_files(self, filenames: List[str]) -> Dict[str, bool]:
        """ì—¬ëŸ¬ íŒŒì¼ ì¼ê´„ ì‚­ì œ"""
        results = {}
        for filename in filenames:
            results[filename] = self.delete_file(filename)
        return results
    
    def delete_all_files(self) -> bool:
        """ëª¨ë“  íŒŒì¼ ì‚­ì œ"""
        try:
            # ë¬¸ì„œ íŒŒì¼ë“¤ ì‚­ì œ
            doc_blobs = list(self.bucket.list_blobs(prefix="documents/"))
            for blob in doc_blobs:
                blob.delete()
            
            # ë©”íƒ€ë°ì´í„° íŒŒì¼ë“¤ ì‚­ì œ
            metadata_blobs = list(self.bucket.list_blobs(prefix="metadata/"))
            for blob in metadata_blobs:
                blob.delete()
            
            logger.info(f"âœ… ëª¨ë“  íŒŒì¼ ì‚­ì œ ì™„ë£Œ: {len(doc_blobs)}ê°œ ë¬¸ì„œ, {len(metadata_blobs)}ê°œ ë©”íƒ€ë°ì´í„°")
            return True
            
        except Exception as e:
            logger.error(f"âŒ ì „ì²´ íŒŒì¼ ì‚­ì œ ì‹¤íŒ¨: {e}")
            return False
    
    def get_embedding_stats(self) -> Dict[str, Any]:
        """ì„ë² ë”© í†µê³„ ì¡°íšŒ"""
        try:
            metadata = self.get_metadata()
            total_files = len(metadata)
            completed_files = sum(1 for m in metadata.values() if m.get('has_embedding', False))
            pending_files = total_files - completed_files
            completion_rate = (completed_files / total_files * 100) if total_files > 0 else 0
            
            return {
                'total_files': total_files,
                'completed_files': completed_files,
                'pending_files': pending_files,
                'completion_rate': round(completion_rate, 2)
            }
            
        except Exception as e:
            logger.error(f"âŒ ì„ë² ë”© í†µê³„ ì¡°íšŒ ì‹¤íŒ¨: {e}")
            return {
                'total_files': 0,
                'completed_files': 0,
                'pending_files': 0,
                'completion_rate': 0
            }
    
    def get_storage_info(self) -> Dict[str, Any]:
        """ì €ì¥ì†Œ ì •ë³´ ì¡°íšŒ (ì¬ì‹œë„ ë¡œì§ í¬í•¨)"""
        max_retries = 3
        for attempt in range(max_retries):
            try:
                # í´ë¼ì´ì–¸íŠ¸ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì€ ê²½ìš° ì¬ì‹œë„
                if not self.client or not self.bucket:
                    logger.info(f"ğŸ”„ í´ë¼ì´ì–¸íŠ¸ ì¬ì´ˆê¸°í™” ì‹œë„ {attempt + 1}/{max_retries}")
                    try:
                        self._initialize_client_with_retry()
                    except Exception as init_error:
                        logger.error(f"âŒ í´ë¼ì´ì–¸íŠ¸ ì¬ì´ˆê¸°í™” ì‹¤íŒ¨: {init_error}")
                        if attempt < max_retries - 1:
                            continue
                        else:
                            return {
                                'type': 'cloud_storage',
                                'error': f'í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì‹¤íŒ¨: {init_error}',
                                'bucket_name': self.bucket_name,
                                'project_id': self.project_id
                            }
                
                # ë²„í‚· ì •ë³´
                bucket_info = {
                    'name': self.bucket_name,
                    'location': self.bucket.location,
                    'storage_class': self.bucket.storage_class,
                    'created': self.bucket.time_created.isoformat() if self.bucket.time_created else None
                }
                
                # íŒŒì¼ í†µê³„
                doc_blobs = list(self.bucket.list_blobs(prefix="documents/"))
                metadata_blobs = list(self.bucket.list_blobs(prefix="metadata/"))
                
                total_size = sum(blob.size for blob in doc_blobs if blob.size)
                
                return {
                    'type': 'cloud_storage',
                    'bucket_info': bucket_info,
                    'total_files': len(doc_blobs),
                    'total_size': total_size,
                    'metadata_files': len(metadata_blobs)
                }
                
            except Exception as e:
                logger.warning(f"âš ï¸ ì €ì¥ì†Œ ì •ë³´ ì¡°íšŒ ì‹¤íŒ¨ (ì‹œë„ {attempt + 1}/{max_retries}): {e}")
                
                if attempt < max_retries - 1:
                    import time
                    wait_time = (attempt + 1) * 2
                    logger.info(f"â³ {wait_time}ì´ˆ í›„ ì¬ì‹œë„...")
                    time.sleep(wait_time)
                else:
                    logger.error(f"âŒ ì €ì¥ì†Œ ì •ë³´ ì¡°íšŒ ìµœì¢… ì‹¤íŒ¨: {e}")
                    return {
                        'type': 'cloud_storage',
                        'error': str(e),
                        'bucket_name': self.bucket_name,
                        'project_id': self.project_id
                    }
