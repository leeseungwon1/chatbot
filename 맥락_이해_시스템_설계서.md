# 맥락 이해 시스템 설계서

## 개요
RAG 시스템에서 사용자의 연속된 질문에 대한 맥락을 이해하고 적절한 답변을 제공하기 위한 다양한 맥락 저장 및 선택 방법들을 정리한 문서입니다.

---

## 1. 최근 N개 방식 (낮은 복잡도)

### 실행 방법
```python
# Flask 세션에 대화 히스토리 저장
session['chat_history'] = []

@app.route('/api/query', methods=['POST'])
def query():
    question = data.get('question')
    chat_history = session.get('chat_history', [])
    
    # 최근 N개 대화만 사용 (N=5)
    recent_context = chat_history[-5:] if len(chat_history) > 5 else chat_history
    
    # 프롬프트에 맥락 포함
    context_text = ""
    for conv in recent_context:
        context_text += f"Q: {conv['question']}\nA: {conv['answer']}\n\n"
    
    prompt = f"""
    이전 대화:
    {context_text}
    
    현재 질문: {question}
    """
    
    answer = rag_system.query_with_context(prompt)
    
    # 새 대화를 히스토리에 추가
    session['chat_history'].append({
        'question': question,
        'answer': answer
    })
    
    # 최대 N개만 유지
    if len(session['chat_history']) > 5:
        session['chat_history'] = session['chat_history'][-5:]
```

### 장점
- **구현 간단**: 10-15줄 코드로 완성
- **빠른 처리**: 추가 계산 없음
- **안정성**: 항상 일정한 맥락 제공
- **비용 절약**: API 호출 횟수 동일
- **메모리 효율**: 최소한의 메모리 사용

### 단점
- **불필요한 맥락**: 관련 없는 이전 대화도 포함
- **토큰 낭비**: 긴 프롬프트로 인한 비용 증가
- **장기 맥락 손실**: N개를 넘어서면 완전 소실
- **참조 문제**: "그것", "저것" 등의 암시적 참조 불가

### 성능
- **처리 시간**: 거의 없음
- **메모리 사용량**: 5-10KB
- **정확도**: 70-80%

---

## 2. 키워드 기반 맥락 선택 (중간 복잡도)

### 실행 방법
```python
def extract_keywords(text):
    """텍스트에서 키워드 추출"""
    stopwords = ['은', '는', '이', '가', '을', '를', '에', '의', '로', '으로', '에서', '에게']
    words = text.split()
    return [word for word in words if word not in stopwords and len(word) > 1]

def select_context_by_keywords(current_question, chat_history, max_contexts=3):
    """키워드 기반 맥락 선택"""
    current_keywords = set(extract_keywords(current_question))
    scored_contexts = []
    
    for conv in chat_history:
        conv_text = conv['question'] + ' ' + conv['answer']
        conv_keywords = set(extract_keywords(conv_text))
        
        # 키워드 겹치는 정도 계산
        overlap = len(current_keywords & conv_keywords)
        if overlap > 0:
            scored_contexts.append((overlap, conv))
    
    # 겹치는 키워드가 많은 순으로 정렬
    scored_contexts.sort(reverse=True)
    return [conv for _, conv in scored_contexts[:max_contexts]]

@app.route('/api/query', methods=['POST'])
def query():
    question = data.get('question')
    chat_history = session.get('chat_history', [])
    
    # 키워드 기반으로 관련 맥락 선택
    relevant_contexts = select_context_by_keywords(question, chat_history)
    
    # 선택된 맥락으로 프롬프트 생성
    context_text = ""
    for conv in relevant_contexts:
        context_text += f"Q: {conv['question']}\nA: {conv['answer']}\n\n"
    
    prompt = f"""
    관련 이전 대화:
    {context_text}
    
    현재 질문: {question}
    """
    
    answer = rag_system.query_with_context(prompt)
    
    # 새 대화를 히스토리에 추가
    session['chat_history'].append({
        'question': question,
        'answer': answer
    })
```

### 장점
- **정확한 맥락**: 관련성 높은 대화만 선택
- **토큰 효율**: 불필요한 정보 제거
- **구현 중간**: 30-50줄 코드
- **확장 가능**: 다양한 키워드 기법 적용 가능

### 단점
- **처리 시간**: 매 질문마다 전체 히스토리 확인
- **키워드 의존**: 키워드 추출 정확도에 따라 성능 좌우
- **동의어 문제**: 같은 의미지만 다른 단어 처리 어려움
- **맥락 단절**: 키워드가 없으면 관련 맥락 놓침

### 성능
- **처리 시간**: 0.1-0.2초 (대화 100개 기준)
- **메모리 사용량**: 50-100KB
- **정확도**: 80-90%

### 최적화 방법
```python
# 1. 슬라이딩 윈도우
recent_history = chat_history[-50:]  # 최근 50개만 확인

# 2. 키워드 인덱싱
keyword_index = {
    "규정": [대화1, 대화5],
    "휴가": [대화2, 대화8]
}

# 3. 배치 처리
if len(chat_history) % 10 == 0:
    update_keyword_index(chat_history)
```

---

## 3. 주제 분류 기반 선택 (중간 복잡도)

### 실행 방법
```python
def classify_topic(text, topic_keywords):
    """텍스트의 주제 분류"""
    text_lower = text.lower()
    topic_scores = {}
    
    for topic, keywords in topic_keywords.items():
        score = sum(1 for keyword in keywords if keyword in text_lower)
        topic_scores[topic] = score
    
    return max(topic_scores, key=topic_scores.get) if topic_scores else "기타"

def select_context_by_topic(current_question, chat_history):
    """주제 기반 맥락 선택"""
    topic_keywords = {
        "회사규정": ["규정", "정책", "제도", "시행일", "변경"],
        "휴가제도": ["휴가", "신청", "승인", "일수", "연차"],
        "급여관련": ["급여", "월급", "계산", "세금", "공제"],
        "복리후생": ["보험", "혜택", "지원", "복지", "수당"],
        "업무절차": ["신청", "절차", "승인", "처리", "문서"]
    }
    
    # 현재 질문의 주제 파악
    current_topic = classify_topic(current_question, topic_keywords)
    
    # 같은 주제의 이전 대화들만 선택
    relevant_contexts = []
    for conv in chat_history:
        conv_topic = classify_topic(conv['question'], topic_keywords)
        if conv_topic == current_topic:
            relevant_contexts.append(conv)
    
    return relevant_contexts[-3:]  # 같은 주제 중 최근 3개
```

### 장점
- **주제 일관성**: 같은 주제의 맥락만 유지
- **구조화된 관리**: 주제별로 체계적 관리
- **확장성**: 새로운 주제 쉽게 추가
- **사용자 경험**: 일관된 답변 제공

### 단점
- **주제 분류 오류**: 잘못된 주제 분류 시 맥락 손실
- **경직성**: 주제가 명확하지 않은 질문 처리 어려움
- **유지보수**: 주제 키워드 수동 관리 필요
- **복합 주제**: 여러 주제가 섞인 질문 처리 어려움

### 성능
- **처리 시간**: 0.1-0.3초
- **메모리 사용량**: 100-200KB
- **정확도**: 85-90%

---

## 4. AI 기반 맥락 선택 (높은 복잡도)

### 실행 방법
```python
def ai_context_selection(current_question, chat_history):
    """AI를 이용한 맥락 선택"""
    # 대화 히스토리를 텍스트로 변환
    history_text = ""
    for i, conv in enumerate(chat_history):
        history_text += f"{i+1}. Q: {conv['question']}\n   A: {conv['answer']}\n\n"
    
    prompt = f"""
    현재 질문: "{current_question}"
    
    이전 대화 히스토리:
    {history_text}
    
    위 대화 중에서 현재 질문과 관련성이 높은 것들을 선택해주세요.
    관련성 점수(0-10)와 함께 JSON 형태로 답변해주세요.
    
    예시:
    {{
        "relevant_contexts": [
            {{"index": 1, "relevance_score": 8.5, "reason": "같은 주제"}},
            {{"index": 3, "relevance_score": 7.2, "reason": "관련 정보"}}
        ]
    }}
    """
    
    response = openai.ChatCompletion.create(
        model="gpt-3.5-turbo",
        messages=[{"role": "user", "content": prompt}],
        temperature=0.1
    )
    
    return parse_context_selection(response.choices[0].message.content)

def parse_context_selection(response_text):
    """AI 응답을 파싱하여 관련 맥락 추출"""
    try:
        import json
        result = json.loads(response_text)
        return result.get('relevant_contexts', [])
    except:
        return []
```

### 장점
- **최고 정확도**: AI가 맥락의 관련성 정확히 판단
- **유연성**: 복잡한 맥락 관계도 이해
- **자동화**: 수동 규칙 설정 불필요
- **지능적**: 암시적 참조도 처리 가능

### 단점
- **높은 비용**: 추가 API 호출로 비용 증가
- **느린 처리**: 0.5-1초 추가 지연
- **복잡한 구현**: 100-200줄 코드 필요
- **의존성**: AI 서비스 의존도 높음

### 성능
- **처리 시간**: 0.5-1초
- **메모리 사용량**: 200-500KB
- **정확도**: 90-95%
- **비용**: 기존 대비 20-30% 증가

---

## 5. 하이브리드 방식 (중간-높은 복잡도)

### 실행 방법
```python
def hybrid_context_selection(current_question, chat_history):
    """하이브리드 맥락 선택"""
    # 1단계: 키워드 기반 1차 필터링
    keyword_contexts = select_context_by_keywords(current_question, chat_history, max_contexts=10)
    
    # 2단계: 시간 가중치 적용
    current_time = datetime.now()
    scored_contexts = []
    
    for conv in keyword_contexts:
        # 유사도 점수
        similarity = calculate_keyword_similarity(current_question, conv)
        
        # 시간 가중치 (최근일수록 높음)
        time_diff = current_time - conv['timestamp']
        time_weight = 1 / (1 + time_diff.days)
        
        # 최종 점수
        final_score = similarity * 0.7 + time_weight * 0.3
        scored_contexts.append((final_score, conv))
    
    # 3단계: 상위 3개 선택
    scored_contexts.sort(reverse=True)
    return [conv for _, conv in scored_contexts[:3]]

def calculate_keyword_similarity(question, conversation):
    """키워드 유사도 계산"""
    q_keywords = set(extract_keywords(question))
    c_keywords = set(extract_keywords(conversation['question'] + ' ' + conversation['answer']))
    
    if len(q_keywords) == 0:
        return 0
    
    overlap = len(q_keywords & c_keywords)
    return overlap / len(q_keywords)
```

### 장점
- **균형잡힌 성능**: 정확도와 속도의 좋은 균형
- **다층 필터링**: 여러 방법의 장점 결합
- **적응성**: 상황에 따라 가중치 조정 가능
- **확장성**: 새로운 방법 쉽게 추가

### 단점
- **복잡한 튜닝**: 여러 파라미터 조정 필요
- **중간 성능**: 각 방법의 한계도 함께 가짐
- **디버깅 어려움**: 문제 발생 시 원인 파악 어려움

### 성능
- **처리 시간**: 0.2-0.4초
- **메모리 사용량**: 150-300KB
- **정확도**: 85-92%

---

## 구현 권장사항

### 1단계: 최근 N개 방식
- **목적**: 빠른 프로토타입 및 기본 기능 구현
- **적용 시기**: 초기 개발 단계
- **코드량**: 10-15줄

### 2단계: 키워드 기반 방식
- **목적**: 성능 개선 및 정확도 향상
- **적용 시기**: 기본 기능 완성 후
- **코드량**: 30-50줄

### 3단계: 하이브리드 방식
- **목적**: 최적화된 성능 제공
- **적용 시기**: 사용자 피드백 반영 후
- **코드량**: 50-100줄

### 4단계: AI 기반 방식
- **목적**: 최고 수준의 정확도
- **적용 시기**: 대규모 서비스 운영 시
- **코드량**: 100-200줄

---

## 성능 비교 요약

| 방식 | 복잡도 | 처리시간 | 정확도 | 비용 | 구현난이도 |
|------|--------|----------|--------|------|------------|
| 최근 N개 | 낮음 | 거의 없음 | 70-80% | 기본 | 매우 쉬움 |
| 키워드 기반 | 중간 | 0.1-0.2초 | 80-90% | 기본 | 쉬움 |
| 주제 분류 | 중간 | 0.1-0.3초 | 85-90% | 기본 | 보통 |
| 하이브리드 | 중간-높음 | 0.2-0.4초 | 85-92% | 기본 | 보통 |
| AI 기반 | 높음 | 0.5-1초 | 90-95% | +20-30% | 어려움 |

---

## 결론

맥락 이해 시스템은 **사용자 경험을 크게 향상**시키는 중요한 기능입니다. 

**추천 구현 순서**:
1. **최근 N개 방식**으로 시작 (빠른 구현)
2. **키워드 기반**으로 개선 (성능 향상)
3. 필요시 **하이브리드** 또는 **AI 기반**으로 고도화

각 방식은 **시스템 부하가 크지 않으면서도** 사용자에게 **연속된 대화의 맥락을 이해하는 자연스러운 경험**을 제공할 수 있습니다.
